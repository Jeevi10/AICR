{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-173a2c8e1d82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnetworks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnetworks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLeNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassificationNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtesters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mattack_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'networks'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#from pushover import notify\n",
    "from random import randint\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import Image, display\n",
    "import dataloader as dl\n",
    "import model as m\n",
    "import networks\n",
    "from networks import LeNet, ClassificationNet\n",
    "from testers import attack_test\n",
    "from resnet import ResNet\n",
    "import gmm as gmm\n",
    "import parameters as p\n",
    "import helper\n",
    "import misc\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "train_loader,test_loader,loader_list = misc.get_dataloaders(\"Lenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_x, _ = next(iter(loader_list[0]))\n",
    "save_image(fixed_x, 'real_image.png')\n",
    "\n",
    "Image('real_image.png')\n",
    "\n",
    "\n",
    "def in_top_k(targets, preds, k):\n",
    "    topk = preds.topk(k,largest=False)[1]\n",
    "    return (targets.unsqueeze(1) == topk).any(dim=1)\n",
    "\n",
    "\n",
    "def cross_corr(centers):\n",
    "    c = centers.view(-1,10*centers.size(1))\n",
    "    corr =torch.matmul(c.T,c)\n",
    "    loss = torch.norm(torch.triu(corr, diagonal=1, out=None))\n",
    "    return 2*loss/corr.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Proximity(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=100, feat_dim=1024, use_gpu=True, margin = 0.0 ):\n",
    "        super(Proximity, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feat_dim = feat_dim\n",
    "        self.use_gpu = use_gpu\n",
    "        self.device = torch.device(\"cuda:1\")\n",
    "        self.margin = margin\n",
    "\n",
    "        if self.use_gpu:\n",
    "            self.centers =  nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n",
    "        else:\n",
    "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n",
    "\n",
    "    def forward(self, x , labels):\n",
    "        batch_size = x.size(0)\n",
    "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n",
    "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n",
    "        distmat.addmm_(1, -2, x, self.centers.t())\n",
    "\n",
    "        classes = torch.arange(self.num_classes).long()\n",
    "        if self.use_gpu: classes = classes.to(self.device)\n",
    "        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n",
    "        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n",
    "        d_y = distmat[mask.clone()]\n",
    "        \n",
    "        \n",
    "        values, indices = torch.topk(distmat,2, dim=1, largest=False, sorted=True, out=None)\n",
    "        d_1 = values[:,0]\n",
    "        d_2 = values[:,1]\n",
    "        \n",
    "        indicators = in_top_k(labels,distmat,1)[:,0]\n",
    "        con_indicators = ~ indicators.clone()\n",
    "        \n",
    "        d_c = d_2*indicators + d_1*con_indicators\n",
    "        \n",
    "        loss = F.relu((d_y-d_c)/(d_y+d_c) + self.margin)\n",
    "        mean_loss = loss.mean()\n",
    "        return mean_loss, torch.argmin(distmat,dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels = fixed_x.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_net = LeNet()\n",
    "model = ClassificationNet(embedding_net, n_classes=p.n_classes).cuda()\n",
    "gmm = gmm.GaussianMixturePrior(p.num_classes, network_weights=list(model.embedding_net.layers.parameters()), pi_zero=0.99).cuda()\n",
    "                                       \n",
    "criterion_prox_256 = Proximity(num_classes=10, feat_dim=256, use_gpu=True,margin=0.75)\n",
    "criterion_prox_1024 = Proximity(num_classes=10, feat_dim=1024, use_gpu=True, margin=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_pre = torch.optim.Adam([{'params':model.parameters()}], lr=1e-3, weight_decay=1e-7)\n",
    "#optimizer_post = torch.optim.Adam([{'params':model.parameters()},\n",
    "#                                 {'params': gmm.means, 'lr': p.lr_mu},\n",
    "#                                 {'params': gmm.gammas, 'lr': p.lr_gamma},\n",
    "#                                 {'params': gmm.rhos, 'lr': p.lr_rho}], lr=p.lr_post)\n",
    "optimizer_post = torch.optim.Adam([{'params':model.parameters()}], lr=5e-3, weight_decay=1e-7)\n",
    "#optimizer_prox_1024 = torch.optim.SGD(criterion_prox_1024.parameters(), lr=0.1)\n",
    "#optimizer_conprox_1024 = torch.optim.SGD(criterion_conprox_1024.parameters(), lr=0.0001)\n",
    "                                         \n",
    "                                         \n",
    "optimizer_prox_256 = torch.optim.SGD(criterion_prox_256.parameters(), lr=0.01)\n",
    "optimizer_prox_1024 = torch.optim.SGD(criterion_prox_1024.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "criterion =  nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rfr reconstructed\n",
    "!rm -rfr softmaxreconstructed\n",
    "!rm -rfr figs\n",
    "!mkdir reconstructed\n",
    "!mkdir softmaxreconstructed\n",
    "!mkdir figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_0 = 50\n",
    "epochs_1 = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.patheffects as PathEffects\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "RS = 123\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',\n",
    "              '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',\n",
    "              '#bcbd22', '#17becf']\n",
    "\n",
    "mnist_classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "def t_sne_gen(data):\n",
    "    fashion_tsne = TSNE(random_state=RS).fit_transform(data.numpy())\n",
    "    #fashion_pca = PCA(n_components=2, svd_solver='full').fit(data.numpy())\n",
    "    #x = fashion_pca.transform(data.numpy())\n",
    "    return fashion_tsne\n",
    "\n",
    "\n",
    "def fashion_scatter(x, colors,name,folder):\n",
    "    # choose a color palette with seaborn.\n",
    "    num_classes = len(np.unique(colors))\n",
    "    palette = np.array(sns.color_palette(\"hls\", num_classes))\n",
    "\n",
    "    # create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40, c=palette[colors.astype(np.int)])\n",
    "    plt.title(name)\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # add the labels for each digit corresponding to the label\n",
    "    txts = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "\n",
    "        # Position of each label at median of data points.\n",
    "\n",
    "        xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "   \n",
    "    plt.savefig(folder+name+'.png')\n",
    "\n",
    "    return f, ax, sc, txts\n",
    "\n",
    "\n",
    "def plot_embeddings(embeddings, targets, xlim=None, ylim=None):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for i in range(10):\n",
    "        #ax = fig.add_subplot(111, projection='3d')\n",
    "        inds = np.where(targets==i)[0]\n",
    "        ax.scatter(embeddings[inds,0], embeddings[inds,1], embeddings[inds,2], alpha=0.5, color=colors[i])\n",
    "    if xlim:\n",
    "        plt.xlim(xlim[0], xlim[1])\n",
    "    if ylim:\n",
    "        plt.ylim(ylim[0], ylim[1])\n",
    "    plt.legend(mnist_classes)\n",
    "\n",
    "def extract_embeddings(dataloader, model, pretrain):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embeddings_1 = np.zeros((len(dataloader.dataset), networks.vis_size))\n",
    "        embeddings_2 = np.zeros((len(dataloader.dataset), networks.vis_size))\n",
    "        labels = np.zeros(len(dataloader.dataset))\n",
    "        k = 0\n",
    "        for images, target in dataloader:\n",
    "            \n",
    "            images = images.cuda()\n",
    "            emb_1, emb_2= model.get_embedding(images, pretrain)\n",
    "            emb_1, emb_2 = emb_1.cpu(), emb_2.cpu()\n",
    "            embeddings_1[k:k+len(images)] = emb_1\n",
    "            embeddings_2[k:k+len(images)] = emb_2\n",
    "            labels[k:k+len(images)] = target.numpy()\n",
    "            k += len(images)\n",
    "    return embeddings_1, embeddings_2, labels\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "correct =0\n",
    "num_example =0\n",
    "test_loss_bce=0\n",
    "test_correct=0\n",
    "test_num_example =0\n",
    "for epoch in range(epochs_0):\n",
    "    model.train()\n",
    "    for idx, (images, target) in enumerate(train_loader):\n",
    "        images, target= images.cuda(), target.cuda()\n",
    "        out, rep_1, rep_2 = model(images, test= False)\n",
    "        loss_bce = criterion(out,target)\n",
    "        #loss_prox_1024 = criterion_prox_1024(rep_1, target) \n",
    "        #loss_conprox_1024 = criterion_conprox_1024(rep_1, target) \n",
    "        #loss_prox_256 = criterion_prox_256(rep_2, target) \n",
    "        #loss_conprox_256= criterion_conprox_256(rep_2, target) \n",
    "        loss = loss_bce #+ loss_prox_1024 + loss_prox_256 - loss_conprox_1024*0.0001 - loss_conprox_256*0.0001\n",
    "        preds = out.data.max(1, keepdim=True)[1]\n",
    "        correct += preds.eq(target.data.view_as(preds)).sum()\n",
    "        num_example += len(target)\n",
    "        optimizer_pre.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_pre.step()\n",
    "        \n",
    "        to_print = \"Epoch[{}/{}] Loss: {:.3f}  Accuracy:  {}\".format(epoch+1,epochs_0, loss.item()/bs, correct.item()/num_example)\n",
    "        \n",
    "        \n",
    "        if idx % 500 == 0:\n",
    "            print(to_print)\n",
    "            \n",
    "            \n",
    "            \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, target in test_loader:\n",
    "            images, target = images.cuda(), target.cuda()\n",
    "            out, rep_1, rep_2= model(images, test=False)\n",
    "            loss_bce = criterion(out,target)\n",
    "            preds = out.data.max(1, keepdim=True)[1]\n",
    "            test_correct += preds.eq(target.data.view_as(preds)).sum()\n",
    "            test_num_example += len(target)\n",
    "            test_loss_bce+=loss_bce.item()\n",
    "            \n",
    "            \n",
    "            \n",
    "    test_loss_bce /= len(test_loader.dataset)\n",
    "    print( \"test_Loss: {:.3f} Test accuracy: {}\".format( test_loss_bce, test_correct.item()/test_num_example))\n",
    "    if epoch %10==0:\n",
    "        val_embeddings_1, val_embeddings_2, val_labels_baseline = extract_embeddings(test_loader, model,False)\n",
    "        plot_embeddings(val_embeddings_1, val_labels_baseline) \n",
    "        plot_embeddings(val_embeddings_2, val_labels_baseline)    \n",
    "        #fashion_scatter(t_sne_gen(rep_2.cpu()), target.cpu().numpy(),\"Clean_data: \"+\"VAE_\"+str(epoch)+\"softmax_rep2\",\"./softmaxreconstructed/\")  \n",
    "        #fashion_scatter(t_sne_gen(rep_1.cpu()), target.cpu().numpy(),\"Clean_data: \"+\"VAE_\"+str(epoch)+\"softmax_rep1\",\"./softmaxreconstructed/\")\n",
    "        attack_test(model, test_loader, nn.CrossEntropyLoss() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "correct =0\n",
    "num_example =0\n",
    "test_loss_bce=0\n",
    "test_correct=0\n",
    "test_num_example =0\n",
    "pre_wts= copy.deepcopy(list(model.embedding_net.layers.parameters()))\n",
    "for epoch in range(epochs_1):\n",
    "    model.train()\n",
    "    for idx, (images, target) in enumerate(train_loader):\n",
    "        images, target= images.cuda(), target.cuda()\n",
    "        out, rep_1, rep_2 = model(images,test=False)\n",
    "        #loss_bce = criterion(out,target)\n",
    "        loss_prox_1024, _ = criterion_prox_1024(rep_1, target) \n",
    "        loss_prox_256, preds = criterion_prox_256(rep_2, target) \n",
    "        loss = loss_prox_256 + loss_prox_1024 + 0.1 * cross_corr(criterion_prox_256.centers)\n",
    "        #preds = out.data.max(1, keepdim=True)[1]\n",
    "        correct += preds.eq(target.data.view_as(preds)).sum()\n",
    "        num_example += len(target)\n",
    "        optimizer_post.zero_grad()\n",
    "        optimizer_prox_1024.zero_grad() \n",
    "        optimizer_prox_256.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer_post.step()\n",
    "      \n",
    "        for param in criterion_prox_256.parameters():\n",
    "            param.grad.data *= (1. /1)\n",
    "        optimizer_prox_256.step()\n",
    "        \n",
    "        \n",
    "        for param in criterion_prox_1024.parameters():\n",
    "            param.grad.data *= (1. /1)\n",
    "        optimizer_prox_256.step()\n",
    "        \n",
    "    \n",
    "        to_print = \"Epoch[{}/{}] Loss: {:.3f}  Accuracy:  {}\".format(epoch+1,epochs_1, loss.item()/bs, correct.item()/num_example)\n",
    "        \n",
    "        \n",
    "        if idx % 500 == 0:\n",
    "            print(to_print)\n",
    "            \n",
    "    #helper.plot_histogram(epoch,idx, pre_wts, list(model.embedding_net.layers.parameters()), list(gmm.parameters()), correct.item()/num_example,\"./figs/\")    \n",
    "            \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, target in test_loader:\n",
    "            images, target = images.cuda(), target.cuda()\n",
    "            out, rep_1, rep_2= model(images, test=False)\n",
    "            loss_bce = criterion(out,target)\n",
    "            loss_prox_256, preds = criterion_prox_256(rep_2, target) \n",
    "            #preds = out.data.max(1, keepdim=True)[1]\n",
    "            test_correct += preds.eq(target.data.view_as(preds)).sum()\n",
    "            test_num_example += len(target)\n",
    "            test_loss_bce+=loss_bce.item()\n",
    "            \n",
    "            \n",
    "            \n",
    "    test_loss_bce /= len(test_loader.dataset)\n",
    "    print( \"test_Loss: {:.3f} Test accuracy: {}\".format( test_loss_bce, test_correct.item()/test_num_example))\n",
    "    \n",
    "            \n",
    "    if epoch %10==0:\n",
    "        val_embeddings_1, val_embeddings_2, val_labels_baseline = extract_embeddings(test_loader, model,True)\n",
    "        plot_embeddings(val_embeddings_1, val_labels_baseline) \n",
    "        plot_embeddings(val_embeddings_2, val_labels_baseline)    \n",
    "        #fashion_scatter(t_sne_gen(rep_2.cpu()), target.cpu().numpy(),\"Clean_data: \"+\"VAE_\"+str(epoch)+\"softmax_rep2\",\"./softmaxreconstructed/\")  \n",
    "        #fashion_scatter(t_sne_gen(rep_1.cpu()), target.cpu().numpy(),\"Clean_data: \"+\"VAE_\"+str(epoch)+\"softmax_rep1\",\"./softmaxreconstructed/\")\n",
    "        attack_test(model, test_loader, nn.CrossEntropyLoss() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
